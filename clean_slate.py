#!/usr/bin/env python3
"""
Clean Slate - Wipe All SERP Analysis Reports
This script will remove all existing SERP analysis data from all service pages.
"""

import os
import sys
from pathlib import Path
import frontmatter
import glob

def wipe_all_serp_reports():
    """Remove all SERP analysis data from all service pages"""
    
    ellie_root = Path(r"C:\Users\rhode\source\repos\EllieEdwardsMarketingLeadgenSite")
    services_dir = ellie_root / "content" / "services"
    
    print(f"üßπ Wiping all SERP analysis reports from: {services_dir}")
    
    if not services_dir.exists():
        print(f"‚ùå Services directory not found: {services_dir}")
        return False
    
    # Find all markdown files in services directory
    service_files = list(services_dir.glob("*.md"))
    
    print(f"üìÑ Found {len(service_files)} service files")
    
    cleaned_count = 0
    
    for service_file in service_files:
        try:
            print(f"\nüîç Processing: {service_file.name}")
            
            # Read the file
            with open(service_file, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            # Check if it has SEO data
            if 'seo' in post.metadata:
                # Check if it has SERP analysis
                if 'serpAnalysis' in post.metadata['seo']:
                    print(f"  üóëÔ∏è  Removing SERP analysis data")
                    del post.metadata['seo']['serpAnalysis']
                    
                    # Also remove lastAnalysisDate if it exists
                    if 'lastAnalysisDate' in post.metadata['seo']:
                        del post.metadata['seo']['lastAnalysisDate']
                    
                    # If SEO section is now empty except for metaTitle, we can leave it
                    # Write the cleaned file
                    with open(service_file, 'w', encoding='utf-8') as f:
                        f.write(frontmatter.dumps(post))
                    
                    print(f"  ‚úÖ Cleaned {service_file.name}")
                    cleaned_count += 1
                else:
                    print(f"  ‚ÑπÔ∏è  No SERP analysis data found")
            else:
                print(f"  ‚ÑπÔ∏è  No SEO section found")
                
        except Exception as e:
            print(f"  ‚ùå Error processing {service_file.name}: {e}")
    
    print(f"\nüéâ Cleaning complete!")
    print(f"üìä Summary:")
    print(f"  - Files processed: {len(service_files)}")
    print(f"  - Files cleaned: {cleaned_count}")
    print(f"  - Files unchanged: {len(service_files) - cleaned_count}")
    
    return True

def verify_clean_slate():
    """Verify that all SERP analysis data has been removed"""
    
    ellie_root = Path(r"C:\Users\rhode\source\repos\EllieEdwardsMarketingLeadgenSite")
    services_dir = ellie_root / "content" / "services"
    
    print(f"\nüîç Verifying clean slate...")
    
    service_files = list(services_dir.glob("*.md"))
    serp_data_found = 0
    
    for service_file in service_files:
        try:
            with open(service_file, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            if 'seo' in post.metadata and 'serpAnalysis' in post.metadata['seo']:
                print(f"  ‚ö†Ô∏è  SERP analysis still found in: {service_file.name}")
                serp_data_found += 1
                
        except Exception as e:
            print(f"  ‚ùå Error checking {service_file.name}: {e}")
    
    if serp_data_found == 0:
        print(f"  ‚úÖ Clean slate verified - no SERP analysis data found")
        return True
    else:
        print(f"  ‚ùå Clean slate failed - {serp_data_found} files still have SERP data")
        return False

if __name__ == "__main__":
    print("üßπ Starting Clean Slate Operation")
    print("=" * 50)
    
    # Step 1: Wipe all reports
    if wipe_all_serp_reports():
        
        # Step 2: Verify clean slate
        if verify_clean_slate():
            print("\nüéâ SUCCESS! All SERP analysis reports have been wiped.")
            print("‚ú® You now have a clean slate to start fresh.")
        else:
            print("\n‚ö†Ô∏è  Warning: Some SERP data may still exist.")
    else:
        print("\n‚ùå Failed to wipe SERP analysis reports.")
    
    print("\nüìã Next steps:")
    print("1. Enhanced multi-report data structure will be implemented")
    print("2. TinaCMS schema will be updated for historical reports")
    print("3. Streamlit app will be enhanced for report history")
